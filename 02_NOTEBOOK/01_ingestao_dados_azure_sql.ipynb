{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba355bb1-8f54-4add-9251-ca4cd096f204",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## [PRÉ REQUISITO] Atividades Desenvolvidas Fora do Ambiente Databricks\n",
    "\n",
    "|Sequência|Ação|Detalhamento\n",
    "|---|---|---|\n",
    "|SEQ-01|Provisionamento do Azure SQL|Provisionamento de um banco de dados no Azure|\n",
    "|SEQ-02|Configuração do Ambiente Azure|Criação de toda a estrutura de tabelas e dados|\n",
    "\n",
    "\n",
    "## Atividades Desenvolvidas no Notebook - 01_ingestao_dados_azure_sql\n",
    "\n",
    "|Sequência|Ação|Detalhamento\n",
    "|---|---|---|\n",
    "|SEQ-01 / SEQ-02|Configuração de Biblioteca|Instalação da Biblioteca \"sqlalchemy\"|\n",
    "|SEQ-03|Consumindo Arquivo JSON|Arquivo com as credenciais de acesso ao Azure SQL Database|\n",
    "|SEQ-04|Selação das Tabelas|Identificar quais serão as tabelas usadas durante o processo de ingestão|\n",
    "|SEQ-05|Extração dos Dados do Azure SQL|Coleta dos Dados do Azure SQL|\n",
    "|SEQ-06|Persistir os Dados em Parquet|Os dados deverão ser persistidos no diretório de cada tabela em formato parquet.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53d1c97f-2470-4a4e-95f0-b09ce013bb57",
     "showTitle": true,
     "title": "SEQ-01 - Configuração da Biblioteca sqlalchemy"
    }
   },
   "outputs": [],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5472f1b1-a2c4-4998-b588-4826f5a88178",
     "showTitle": true,
     "title": "SEQ-02 - Importação das Bibliotecas"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import __version__ as sa_version, create_engine, text\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e59b0d4-1188-4a31-93ff-0c20316e403f",
     "showTitle": true,
     "title": "SEQ-03 - Consumindo Arquivo JSON"
    }
   },
   "outputs": [],
   "source": [
    "dfjson =  pd.read_json(\"https://raw.githubusercontent.com/dbaassists/Projeto_BI_Zero_TO_DW/main/04_ARQUIVO_CONFIG/config_azure_sql.json?token=GHSAT0AAAAAACHGS3USEFHIPSC2NR3PNHTOZKNR2ZQ\")\n",
    "\n",
    "server = dfjson['Config']['server']\n",
    "database = dfjson['Config']['database']\n",
    "username = dfjson['Config']['username']\n",
    "password = dfjson['Config']['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960be4a2-c669-4c63-897e-a0242edc2c16",
     "showTitle": true,
     "title": "SEQ-04 - Mapear Todas as Tabelas Existentes no Azure SQL"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    ".format(\"jdbc\") \\\n",
    ".option(\"url\", f\"jdbc:sqlserver://{server};database={database}\") \\\n",
    ".option(\"query\", \"\"\"SELECT s.name + '.' +  t.NAME AS Nome_Tabela \n",
    "                        FROM sys.tables t\n",
    "                        INNER JOIN sys.schemas s\n",
    "                        ON t.schema_id = s.schema_id\"\"\") \\\n",
    ".option(\"user\", f\"{username}\") \\\n",
    ".option(\"password\", f\"{password}\") \\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf05b1cd-63be-4761-bd68-07891e4d57e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d7f0f82-1430-453e-89c2-494d60e1aac5",
     "showTitle": true,
     "title": "SEQ-05 - Coletar os Dados das Tabelas Existentes no Azure SQL e Salvando em Parquet na Caamda Landing_Zone"
    }
   },
   "outputs": [],
   "source": [
    "lista_tabelas = df.collect()\n",
    "\n",
    "for tabela in lista_tabelas:\n",
    "\n",
    "    tabela_paquet = tabela['Nome_Tabela'].replace('dbo.','').lower()\n",
    "\n",
    "    print(tabela_paquet)\n",
    "\n",
    "    diretorio_parquet = \"dbfs:/FileStore/tables/landing_zone/{0}\".format(tabela_paquet)\n",
    "\n",
    "    df = (spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\", f\"jdbc:sqlserver://{server};database={database}\") \\\n",
    "    .option(\"query\", \"SELECT * FROM {0}\".format(tabela['Nome_Tabela']))\n",
    "    .option(\"user\", f\"{username}\") \\\n",
    "    .option(\"password\", f\"{password}\") \\\n",
    "    .load()\n",
    "    )\n",
    "    \n",
    "    (df.write\n",
    "    .format('parquet')\n",
    "    .mode(\"overwrite\")\n",
    "    .save(diretorio_parquet)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1934667511695067,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingestao_dados_azure_sql",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
